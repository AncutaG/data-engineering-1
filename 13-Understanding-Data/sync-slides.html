<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Week 13 - sync session">
  <title>Fundamentals of Data Engineering</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/mids.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">Fundamentals of Data Engineering</h1>
  <h2 class="author">Week 13 - sync session</h2>
  <img class="frontPageSlogan" src="http://people.ischool.berkeley.edu/~mark.mims/course-development/2017-mids-w205/media/datascience-at-berkeley.png"/>
</section>

<section id="section" class="slide level1">
<h1></h1>
<section id="get-started" class="level2">
<h2>Get Started</h2>
<pre><code>git pull in ~/w205/course-content
mkdir ~/w205/full-stack2/
cd ~/w205/full-stack2
docker-compose pull
cp ~/w205/course-content/13-Understanding-Data/docker-compose.yml .
cp ~/w205/course-content/13-Understanding-Data/*.py .
</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-1" class="slide level1">
<h1></h1>
<section id="section-2" class="level2" data-background="images/pipeline-steel-thread-for-mobile-app.svg">
<h2></h2>
<aside class="notes">
<p>Let’s walk through this - user interacts with mobile app - mobile app makes API calls to web services - API server handles requests: - handles actual business requirements (e.g., process purchase) - logs events to kafka - spark then: - pulls events from kafka - filters/flattens/transforms events - writes them to storage - presto then queries those events</p>
</aside>
</section>
</section>
<section id="section-3" class="slide level1">
<h1></h1>
<section id="flask-kafka-spark-hadoop-presto-part-ii" class="level2">
<h2>Flask-Kafka-Spark-Hadoop-Presto Part II</h2>
<aside class="notes">
<ul>
<li>last week we did spark from files</li>
<li>ended with spark files reading from kafka, did some munging events, extracted events, json explode, did some filtering for event types.</li>
</ul>
</aside>
</section>
</section>
<section id="section-4" class="slide level1">
<h1></h1>
<section id="setup" class="level2">
<h2>Setup</h2>
</section>
<section id="the-docker-compose.yml" class="level2">
<h2>The <code>docker-compose.yml</code></h2>
<p>Create a <code>docker-compose.yml</code> with the following</p>
<pre><code>---
version: &#39;2&#39;
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    expose:
      - &quot;2181&quot;
      - &quot;2888&quot;
      - &quot;32181&quot;
      - &quot;3888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    expose:
      - &quot;9092&quot;
      - &quot;29092&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  cloudera:
    image: midsw205/hadoop:0.0.1
    hostname: cloudera
    expose:
      - &quot;8020&quot; # nn
      - &quot;8888&quot; # hue
      - &quot;9083&quot; # hive thrift
      - &quot;10000&quot; # hive jdbc
      - &quot;50070&quot; # nn http
    ports:
      - &quot;8888:8888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  spark:
    image: midsw205/spark-python:0.0.6
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;8888&quot;
    #ports:
    #  - &quot;8888:8888&quot;
    depends_on:
      - cloudera
    environment:
      HADOOP_NAMENODE: cloudera
      HIVE_THRIFTSERVER: cloudera:9083
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;
    command: bash

  presto:
    image: midsw205/presto:0.0.1
    hostname: presto
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;8080&quot;
    environment:
      HIVE_THRIFTSERVER: cloudera:9083
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  mids:
    image: midsw205/base:0.1.9
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;5000&quot;
    ports:
      - &quot;5000:5000&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;</code></pre>
<aside class="notes">

</aside>
</section>
<section id="spin-up-the-cluster" class="level2">
<h2>Spin up the cluster</h2>
<pre><code>docker-compose up -d</code></pre>
<aside class="notes">
<p>Now spin up the cluster</p>
<pre><code>docker-compose up -d</code></pre>
</aside>
</section>
<section id="web-app" class="level2">
<h2>Web-app</h2>
<ul>
<li>Take our instrumented web-app from before <code>~/w205/full-stack/game_api.py</code></li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="im">from</span> kafka <span class="im">import</span> KafkaProducer</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="im">from</span> flask <span class="im">import</span> Flask, request</a>
<a class="sourceLine" id="cb5-5" data-line-number="5"></a>
<a class="sourceLine" id="cb5-6" data-line-number="6">app <span class="op">=</span> Flask(<span class="va">__name__</span>)</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">producer <span class="op">=</span> KafkaProducer(bootstrap_servers<span class="op">=</span><span class="st">&#39;kafka:29092&#39;</span>)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="kw">def</span> log_to_kafka(topic, event):</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">    event.update(request.headers)</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">    producer.send(topic, json.dumps(event).encode())</a>
<a class="sourceLine" id="cb5-13" data-line-number="13"></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"></a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="at">@app.route</span>(<span class="st">&quot;/&quot;</span>)</a>
<a class="sourceLine" id="cb5-16" data-line-number="16"><span class="kw">def</span> default_response():</a>
<a class="sourceLine" id="cb5-17" data-line-number="17">    default_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;default&#39;</span>}</a>
<a class="sourceLine" id="cb5-18" data-line-number="18">    log_to_kafka(<span class="st">&#39;events&#39;</span>, default_event)</a>
<a class="sourceLine" id="cb5-19" data-line-number="19">    <span class="cf">return</span> <span class="st">&quot;This is the default response!</span><span class="ch">\n</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb5-20" data-line-number="20"></a>
<a class="sourceLine" id="cb5-21" data-line-number="21"></a>
<a class="sourceLine" id="cb5-22" data-line-number="22"><span class="at">@app.route</span>(<span class="st">&quot;/purchase_a_sword&quot;</span>)</a>
<a class="sourceLine" id="cb5-23" data-line-number="23"><span class="kw">def</span> purchase_a_sword():</a>
<a class="sourceLine" id="cb5-24" data-line-number="24">    purchase_sword_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;purchase_sword&#39;</span>}</a>
<a class="sourceLine" id="cb5-25" data-line-number="25">    log_to_kafka(<span class="st">&#39;events&#39;</span>, purchase_sword_event)</a>
<a class="sourceLine" id="cb5-26" data-line-number="26">    <span class="cf">return</span> <span class="st">&quot;Sword Purchased!</span><span class="ch">\n</span><span class="st">&quot;</span></a></code></pre></div>
<aside class="notes">
<p>full blown one that adds in request headers</p>
</aside>
</section>
<section id="run-flask" class="level2">
<h2>run flask</h2>
<pre><code>docker-compose exec mids \
  env FLASK_APP=/w205/full-stack/game_api.py \
  flask run --host 0.0.0.0</code></pre>
<aside class="notes">
<pre><code>docker-compose exec mids env FLASK_APP=/w205/full-stack/game_api.py flask run --host 0.0.0.0</code></pre>
</aside>
</section>
<section id="set-up-to-watch-kafka" class="level2">
<h2>Set up to watch kafka</h2>
<pre><code>docker-compose exec mids \
  kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
<aside class="notes">
<ul>
<li>new terminal window, leave up</li>
<li>running kafkacat without -e so it will run continuously</li>
</ul>
<pre><code>docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
</aside>
</section>
<section id="apache-bench-to-generate-data" class="level2">
<h2>Apache Bench to generate data</h2>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<aside class="notes">
<ul>
<li>Choose to generate events with apache bench, curl from browser, but not mixing for now.</li>
<li>generating 10 events for now, can up that as much as needed, e.g., 100K</li>
</ul>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
</aside>
</section>
</section>
<section id="section-5" class="slide level1">
<h1></h1>
<section id="some-spark-to-write-events" class="level2">
<h2>Some Spark to Write Events</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb18-7" data-line-number="7"></a>
<a class="sourceLine" id="cb18-8" data-line-number="8"></a>
<a class="sourceLine" id="cb18-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb18-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb18-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb18-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb18-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"></a>
<a class="sourceLine" id="cb18-16" data-line-number="16"></a>
<a class="sourceLine" id="cb18-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb18-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb18-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb18-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb18-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb18-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-23" data-line-number="23">        .getOrCreate()</a>
<a class="sourceLine" id="cb18-24" data-line-number="24"></a>
<a class="sourceLine" id="cb18-25" data-line-number="25">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb18-26" data-line-number="26">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb18-27" data-line-number="27">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-28" data-line-number="28">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-29" data-line-number="29">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-30" data-line-number="30">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-31" data-line-number="31">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-32" data-line-number="32">        .load()</a>
<a class="sourceLine" id="cb18-33" data-line-number="33"></a>
<a class="sourceLine" id="cb18-34" data-line-number="34">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-35" data-line-number="35">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb18-36" data-line-number="36">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-37" data-line-number="37">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb18-38" data-line-number="38"></a>
<a class="sourceLine" id="cb18-39" data-line-number="39">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-40" data-line-number="40">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb18-41" data-line-number="41">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-42" data-line-number="42">        .toDF()</a>
<a class="sourceLine" id="cb18-43" data-line-number="43">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb18-44" data-line-number="44">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb18-45" data-line-number="45"></a>
<a class="sourceLine" id="cb18-46" data-line-number="46">    extracted_purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-47" data-line-number="47">        .write <span class="op">\</span></a>
<a class="sourceLine" id="cb18-48" data-line-number="48">        .mode(<span class="st">&#39;overwrite&#39;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-49" data-line-number="49">        .parquet(<span class="st">&#39;/tmp/purchases&#39;</span>)</a>
<a class="sourceLine" id="cb18-50" data-line-number="50"></a>
<a class="sourceLine" id="cb18-51" data-line-number="51"></a>
<a class="sourceLine" id="cb18-52" data-line-number="52"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb18-53" data-line-number="53">    main()</a></code></pre></div>
</section>
<section id="run-this" class="level2">
<h2>Run this</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/filtered_writes.py</code></pre>
</section>
<section id="see-purchases-in-hdfs" class="level2">
<h2>See purchases in hdfs</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/purchases/</code></pre>
</section>
</section>
<section id="section-6" class="slide level1">
<h1></h1>
<section id="queries-from-spark" class="level2">
<h2>Queries from Spark</h2>
<p>We ran this in a notebook</p>
<pre><code>purchases = spark.read.parquet(&#39;/tmp/purchases&#39;)
purchases.show()
purchases.registerTempTable(&#39;purchases&#39;)
purchases_by_example2 = spark.sql(&quot;select * from purchases where Host = &#39;example2.com&#39;&quot;)
purchases_by_example2.show()
newdf = purchases_by_example2.toPandas()
newdf.describe()</code></pre>
<aside class="notes">
<ul>
<li>Transition here?</li>
</ul>
</aside>
</section>
</section>
<section id="section-7" class="slide level1">
<h1></h1>
<section id="queries-from-presto" class="level2">
<h2>Queries from Presto</h2>
</section>
<section id="hive-metastore" class="level2">
<h2>Hive metastore</h2>
<ul>
<li>Track schema</li>
<li>Create a table</li>
</ul>
<aside class="notes">
<ul>
<li><p>The Hive metastore is a really common tool used to keep track of schema for tables used throughout the Hadoop and Spark ecosystem.</p></li>
<li><p>To “expose” the schema for our “purchases”… we need to create a table in the hive metastore.</p></li>
<li>There are two ways</li>
</ul>
</aside>
</section>
<section id="hard-way" class="level2">
<h2>Hard Way</h2>
<pre><code>docker-compose exec cloudera hive</code></pre>
<aside class="notes">
<ul>
<li>Run hive in the hadoop container</li>
</ul>
</aside>
</section>
<section id="section-8" class="level2">
<h2></h2>
<div class="sourceCode" id="cb23"><pre class="sourceCode sql"><code class="sourceCode sql"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">create</span> external <span class="kw">table</span> <span class="kw">if</span> <span class="kw">not</span> <span class="kw">exists</span> default.purchases2 (</a>
<a class="sourceLine" id="cb23-2" data-line-number="2">    Accept string,</a>
<a class="sourceLine" id="cb23-3" data-line-number="3">    Host string,</a>
<a class="sourceLine" id="cb23-4" data-line-number="4">    User_Agent string,</a>
<a class="sourceLine" id="cb23-5" data-line-number="5">    event_type string,</a>
<a class="sourceLine" id="cb23-6" data-line-number="6">    <span class="dt">timestamp</span> string</a>
<a class="sourceLine" id="cb23-7" data-line-number="7">  )</a>
<a class="sourceLine" id="cb23-8" data-line-number="8">  stored <span class="kw">as</span> parquet </a>
<a class="sourceLine" id="cb23-9" data-line-number="9">  location <span class="st">&#39;/tmp/purchases&#39;</span></a>
<a class="sourceLine" id="cb23-10" data-line-number="10">  tblproperties (<span class="ot">&quot;parquet.compress&quot;</span>=<span class="ot">&quot;SNAPPY&quot;</span>);</a></code></pre></div>
<aside class="notes">
<pre><code>create external table if not exists default.purchases2 (Accept string, Host string, User_Agent string, event_type string, timestamp string) stored as parquet location &#39;/tmp/purchases&#39;  tblproperties (&quot;parquet.compress&quot;=&quot;SNAPPY&quot;);</code></pre>
</aside>
</section>
<section id="or-we-can-do-this-an-easier-way" class="level2">
<h2>Or… we can do this an easier way</h2>
<pre><code>docker-compose exec spark pyspark</code></pre>
<aside class="notes">
<ul>
<li>run spark</li>
</ul>
</aside>
</section>
<section id="section-9" class="level2">
<h2></h2>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb26-1" data-line-number="1">df <span class="op">=</span> spark.read.parquet(<span class="st">&#39;/tmp/purchases&#39;</span>)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">df.registerTempTable(<span class="st">&#39;purchases&#39;</span>)</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">query <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb26-4" data-line-number="4"><span class="st">create external table purchase_events</span></a>
<a class="sourceLine" id="cb26-5" data-line-number="5"><span class="st">  stored as parquet</span></a>
<a class="sourceLine" id="cb26-6" data-line-number="6"><span class="st">  location &#39;/tmp/purchase_events&#39;</span></a>
<a class="sourceLine" id="cb26-7" data-line-number="7"><span class="st">  as</span></a>
<a class="sourceLine" id="cb26-8" data-line-number="8"><span class="st">  select * from purchases</span></a>
<a class="sourceLine" id="cb26-9" data-line-number="9"><span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb26-10" data-line-number="10">spark.sql(query)</a></code></pre></div>
<aside class="notes">
<pre><code>spark.sql(&quot;create external table purchase_events stored as parquet location &#39;/tmp/purchase_events&#39; as select * from purchases&quot;)</code></pre>
</aside>
</section>
<section id="can-just-include-in-job" class="level2">
<h2>Can just include in job</h2>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb28-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb28-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb28-7" data-line-number="7"></a>
<a class="sourceLine" id="cb28-8" data-line-number="8"></a>
<a class="sourceLine" id="cb28-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb28-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb28-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb28-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb28-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb28-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb28-15" data-line-number="15"></a>
<a class="sourceLine" id="cb28-16" data-line-number="16"></a>
<a class="sourceLine" id="cb28-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb28-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb28-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb28-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb28-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb28-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-23" data-line-number="23">        .enableHiveSupport() <span class="op">\</span></a>
<a class="sourceLine" id="cb28-24" data-line-number="24">        .getOrCreate()</a>
<a class="sourceLine" id="cb28-25" data-line-number="25"></a>
<a class="sourceLine" id="cb28-26" data-line-number="26">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb28-27" data-line-number="27">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb28-28" data-line-number="28">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-29" data-line-number="29">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-30" data-line-number="30">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-31" data-line-number="31">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-32" data-line-number="32">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-33" data-line-number="33">        .load()</a>
<a class="sourceLine" id="cb28-34" data-line-number="34"></a>
<a class="sourceLine" id="cb28-35" data-line-number="35">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb28-36" data-line-number="36">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb28-37" data-line-number="37">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-38" data-line-number="38">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb28-39" data-line-number="39"></a>
<a class="sourceLine" id="cb28-40" data-line-number="40">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb28-41" data-line-number="41">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb28-42" data-line-number="42">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-43" data-line-number="43">        .toDF()</a>
<a class="sourceLine" id="cb28-44" data-line-number="44">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb28-45" data-line-number="45">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb28-46" data-line-number="46"></a>
<a class="sourceLine" id="cb28-47" data-line-number="47">    extracted_purchase_events.registerTempTable(<span class="st">&quot;extracted_purchase_events&quot;</span>)</a>
<a class="sourceLine" id="cb28-48" data-line-number="48"></a>
<a class="sourceLine" id="cb28-49" data-line-number="49">    spark.sql(<span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb28-50" data-line-number="50"><span class="st">        create external table purchases</span></a>
<a class="sourceLine" id="cb28-51" data-line-number="51"><span class="st">        stored as parquet</span></a>
<a class="sourceLine" id="cb28-52" data-line-number="52"><span class="st">        location &#39;/tmp/purchases&#39;</span></a>
<a class="sourceLine" id="cb28-53" data-line-number="53"><span class="st">        as</span></a>
<a class="sourceLine" id="cb28-54" data-line-number="54"><span class="st">        select * from extracted_purchase_events</span></a>
<a class="sourceLine" id="cb28-55" data-line-number="55"><span class="st">    &quot;&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb28-56" data-line-number="56"></a>
<a class="sourceLine" id="cb28-57" data-line-number="57"></a>
<a class="sourceLine" id="cb28-58" data-line-number="58"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb28-59" data-line-number="59">    main()</a></code></pre></div>
</section>
<section id="run-this-1" class="level2">
<h2>Run this</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/write_hive_table.py</code></pre>
</section>
<section id="see-it-wrote-to-hdfs" class="level2">
<h2>See it wrote to hdfs</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/</code></pre>
</section>
<section id="and-now" class="level2">
<h2>and now …</h2>
<ul>
<li>Query this with presto</li>
</ul>
<pre><code>docker-compose exec presto presto --server presto:8080 --catalog hive --schema default</code></pre>
</section>
<section id="experiment" class="level2">
<h2>experiment</h2>
<pre><code>presto:default&gt; show tables;
   Table   
-----------
 purchases 
(1 row)

Query 20180404_224746_00009_zsma3, FINISHED, 1 node
Splits: 2 total, 1 done (50.00%)
0:00 [1 rows, 34B] [10 rows/s, 342B/s]</code></pre>
</section>
<section id="section-10" class="level2">
<h2></h2>
<pre><code>presto:default&gt; describe purchases;
   Column   |  Type   | Comment 
------------+---------+---------
 accept     | varchar |         
 host       | varchar |         
 user-agent | varchar |         
 event_type | varchar |         
 timestamp  | varchar |         
(5 rows)

Query 20180404_224828_00010_zsma3, FINISHED, 1 node
Splits: 2 total, 1 done (50.00%)
0:00 [5 rows, 344B] [34 rows/s, 2.31KB/s]</code></pre>
</section>
<section id="section-11" class="level2">
<h2></h2>
<pre><code>presto:default&gt; select * from purchases;
 accept |       host        |   user-agent    |   event_type   |        timestamp        
--------+-------------------+-----------------+----------------+-------------------------
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.124 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.128 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.131 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.135 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.138
 ...</code></pre>
</section>
</section>
<section id="section-12" class="slide level1">
<h1></h1>
<section id="streaming" class="level2">
<h2>Streaming</h2>
</section>
<section id="simpler-spark" class="level2">
<h2>Simpler spark</h2>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb35-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb35-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb35-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb35-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb35-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb35-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb35-8" data-line-number="8"></a>
<a class="sourceLine" id="cb35-9" data-line-number="9"></a>
<a class="sourceLine" id="cb35-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb35-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb35-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb35-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb35-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb35-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb35-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb35-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb35-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb35-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb35-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb35-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb35-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb35-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb35-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb35-25" data-line-number="25"></a>
<a class="sourceLine" id="cb35-26" data-line-number="26"></a>
<a class="sourceLine" id="cb35-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb35-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb35-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb35-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb35-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb35-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb35-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb35-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb35-35" data-line-number="35"></a>
<a class="sourceLine" id="cb35-36" data-line-number="36"></a>
<a class="sourceLine" id="cb35-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb35-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb35-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb35-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb35-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb35-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb35-44" data-line-number="44"></a>
<a class="sourceLine" id="cb35-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb35-46" data-line-number="46">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb35-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-50" data-line-number="50">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-51" data-line-number="51">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-52" data-line-number="52">        .load()</a>
<a class="sourceLine" id="cb35-53" data-line-number="53"></a>
<a class="sourceLine" id="cb35-54" data-line-number="54">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb35-55" data-line-number="55">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-56" data-line-number="56">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb35-57" data-line-number="57">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb35-58" data-line-number="58">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb35-59" data-line-number="59">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb35-60" data-line-number="60">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb35-61" data-line-number="61"></a>
<a class="sourceLine" id="cb35-62" data-line-number="62">    sword_purchases.printSchema()</a>
<a class="sourceLine" id="cb35-63" data-line-number="63">    sword_purchases.show(<span class="dv">100</span>)</a>
<a class="sourceLine" id="cb35-64" data-line-number="64"></a>
<a class="sourceLine" id="cb35-65" data-line-number="65"></a>
<a class="sourceLine" id="cb35-66" data-line-number="66"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb35-67" data-line-number="67">    main()</a></code></pre></div>
</section>
<section id="run" class="level2">
<h2>Run</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/filter_swords_batch.py</code></pre>
</section>
<section id="turn-that-into-a-stream" class="level2">
<h2>Turn that into a stream</h2>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb37-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb37-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb37-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb37-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb37-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb37-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb37-8" data-line-number="8"></a>
<a class="sourceLine" id="cb37-9" data-line-number="9"></a>
<a class="sourceLine" id="cb37-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb37-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb37-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb37-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb37-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb37-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb37-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb37-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb37-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb37-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb37-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb37-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb37-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb37-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb37-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb37-25" data-line-number="25"></a>
<a class="sourceLine" id="cb37-26" data-line-number="26"></a>
<a class="sourceLine" id="cb37-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb37-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb37-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb37-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb37-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb37-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb37-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb37-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb37-35" data-line-number="35"></a>
<a class="sourceLine" id="cb37-36" data-line-number="36"></a>
<a class="sourceLine" id="cb37-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb37-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb37-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb37-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb37-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb37-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb37-44" data-line-number="44"></a>
<a class="sourceLine" id="cb37-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb37-46" data-line-number="46">        .readStream <span class="op">\</span></a>
<a class="sourceLine" id="cb37-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-50" data-line-number="50">        .load()</a>
<a class="sourceLine" id="cb37-51" data-line-number="51"></a>
<a class="sourceLine" id="cb37-52" data-line-number="52">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb37-53" data-line-number="53">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-54" data-line-number="54">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb37-55" data-line-number="55">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb37-56" data-line-number="56">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb37-57" data-line-number="57">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-58" data-line-number="58">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb37-59" data-line-number="59"></a>
<a class="sourceLine" id="cb37-60" data-line-number="60">    query <span class="op">=</span> sword_purchases <span class="op">\</span></a>
<a class="sourceLine" id="cb37-61" data-line-number="61">        .writeStream <span class="op">\</span></a>
<a class="sourceLine" id="cb37-62" data-line-number="62">        .<span class="bu">format</span>(<span class="st">&quot;console&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb37-63" data-line-number="63">        .start()</a>
<a class="sourceLine" id="cb37-64" data-line-number="64"></a>
<a class="sourceLine" id="cb37-65" data-line-number="65">    query.awaitTermination()</a>
<a class="sourceLine" id="cb37-66" data-line-number="66"></a>
<a class="sourceLine" id="cb37-67" data-line-number="67"></a>
<a class="sourceLine" id="cb37-68" data-line-number="68"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb37-69" data-line-number="69">    main()</a></code></pre></div>
</section>
<section id="run-it" class="level2">
<h2>Run it</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack/filter_swords_stream.py</code></pre>
</section>
<section id="kick-some-more-events" class="level2">
<h2>Kick some more events</h2>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<p>::: notes</p>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
</section>
<section id="write-from-a-stream" class="level2">
<h2>Write from a stream</h2>
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb47-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb47-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb47-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb47-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb47-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb47-8" data-line-number="8"></a>
<a class="sourceLine" id="cb47-9" data-line-number="9"></a>
<a class="sourceLine" id="cb47-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb47-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb47-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb47-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb47-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb47-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb47-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb47-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb47-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb47-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb47-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb47-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb47-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb47-25" data-line-number="25"></a>
<a class="sourceLine" id="cb47-26" data-line-number="26"></a>
<a class="sourceLine" id="cb47-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb47-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb47-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb47-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb47-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb47-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb47-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb47-35" data-line-number="35"></a>
<a class="sourceLine" id="cb47-36" data-line-number="36"></a>
<a class="sourceLine" id="cb47-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb47-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb47-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb47-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb47-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb47-44" data-line-number="44"></a>
<a class="sourceLine" id="cb47-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb47-46" data-line-number="46">        .readStream <span class="op">\</span></a>
<a class="sourceLine" id="cb47-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-50" data-line-number="50">        .load()</a>
<a class="sourceLine" id="cb47-51" data-line-number="51"></a>
<a class="sourceLine" id="cb47-52" data-line-number="52">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb47-53" data-line-number="53">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-54" data-line-number="54">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb47-55" data-line-number="55">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb47-56" data-line-number="56">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb47-57" data-line-number="57">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-58" data-line-number="58">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb47-59" data-line-number="59"></a>
<a class="sourceLine" id="cb47-60" data-line-number="60">    sink <span class="op">=</span> sword_purchases <span class="op">\</span></a>
<a class="sourceLine" id="cb47-61" data-line-number="61">        .writeStream <span class="op">\</span></a>
<a class="sourceLine" id="cb47-62" data-line-number="62">        .<span class="bu">format</span>(<span class="st">&quot;parquet&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-63" data-line-number="63">        .option(<span class="st">&quot;checkpointLocation&quot;</span>, <span class="st">&quot;/tmp/checkpoints_for_sword_purchases&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-64" data-line-number="64">        .option(<span class="st">&quot;path&quot;</span>, <span class="st">&quot;/tmp/sword_purchases&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-65" data-line-number="65">        .trigger(processingTime<span class="op">=</span><span class="st">&quot;10 seconds&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb47-66" data-line-number="66">        .start()</a>
<a class="sourceLine" id="cb47-67" data-line-number="67"></a>
<a class="sourceLine" id="cb47-68" data-line-number="68">    sink.awaitTermination()</a>
<a class="sourceLine" id="cb47-69" data-line-number="69"></a>
<a class="sourceLine" id="cb47-70" data-line-number="70"></a>
<a class="sourceLine" id="cb47-71" data-line-number="71"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb47-72" data-line-number="72">    main()</a></code></pre></div>
</section>
<section id="run-it-1" class="level2">
<h2>Run it</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/write_swords_stream.py</code></pre>
</section>
<section id="feed-it" class="level2">
<h2>Feed it</h2>
<pre><code>while true; do
  docker-compose exec mids \
    ab -n 10 -H &quot;Host: user1.comcast.com&quot; \
      http://localhost:5000/purchase_a_sword
done</code></pre>
<aside class="notes">
<pre><code>while true; do docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword; done</code></pre>
</aside>
</section>
<section id="check-what-it-wrote-to-hadoop" class="level2">
<h2>Check what it wrote to Hadoop</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases</code></pre>
</section>
</section>
<section id="section-13" class="slide level1">
<h1></h1>
<section id="down" class="level2">
<h2>down</h2>
<pre><code>docker-compose down</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-14" class="slide level1">
<h1></h1>
<section id="summary" class="level2">
<h2>summary</h2>
</section>
<section id="section-15" class="level2" data-background="images/pipeline-steel-thread-for-mobile-app.svg">
<h2></h2>
</section>
</section>
<section id="section-16" class="slide level1">
<h1></h1>
<p><img class="logo" src="images/berkeley-school-of-information-logo.png"/></p>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Transition style
        transition: 'linear', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
