<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Week 12 - sync session">
  <title>Fundamentals of Data Engineering</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/mids.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">Fundamentals of Data Engineering</h1>
  <h2 class="author">Week 12 - sync session</h2>
  <img class="frontPageSlogan" src="http://people.ischool.berkeley.edu/~mark.mims/course-development/2017-mids-w205/media/datascience-at-berkeley.png"/>
</section>

<section id="section" class="slide level1">
<h1></h1>
<section id="assignment-review" class="level2">
<h2>Assignment Review</h2>
<ul>
<li>Review your Assignment 11</li>
<li>Get ready to share</li>
<li><code>docker pull midsw205/base:latest</code></li>
<li><code>git pull</code> in <code>~/w205/course-content</code></li>
</ul>
<aside class="notes">
<ul>
<li>Breakout at about 5 after the hour:</li>
<li>Check in with each group</li>
<li>have students share screen</li>
</ul>
</aside>
</section>
<section id="due-friday-pr" class="level2">
<h2>Due Friday (PR)</h2>
</section>
</section>
<section id="section-1" class="slide level1">
<h1></h1>
<section id="section-2" class="level2" data-background="images/pipeline-steel-thread-for-mobile-app.svg">
<h2></h2>
<aside class="notes">
<p>Letâ€™s walk through this - user interacts with mobile app - mobile app makes API calls to web services - API server handles requests: - handles actual business requirements (e.g., process purchase) - logs events to kafka - spark then: - pulls events from kafka - filters/flattens/transforms events - writes them to storage - presto then queries those events</p>
</aside>
</section>
</section>
<section id="section-3" class="slide level1">
<h1></h1>
<section id="flask-kafka-spark-hadoop-presto-part-i" class="level2">
<h2>Flask-Kafka-Spark-Hadoop-Presto Part I</h2>
<aside class="notes">
<ul>
<li>last week we did spark from files</li>
<li>ended with spark files reading from kafka, did some munging events, extracted events, json explode, did some filtering for event types.</li>
</ul>
</aside>
</section>
</section>
<section id="section-4" class="slide level1">
<h1></h1>
<section id="setup" class="level2">
<h2>Setup</h2>
</section>
<section id="set-up-directory-get-docker-compose" class="level2">
<h2>Set up directory, get docker-compose</h2>
<pre><code>mkdir ~/w205/full-stack/
cd ~/w205/full-stack
cp ~/w205/course-content/12-Querying-Data-II/docker-compose.yml .
cp ~/w205/course-content/12-Querying-Data-II/*.py .</code></pre>
<aside class="notes">

</aside>
</section>
<section id="the-docker-compose.yml" class="level2">
<h2>The <code>docker-compose.yml</code></h2>
<p>Create a <code>docker-compose.yml</code> with the following</p>
<pre><code>---
version: &#39;2&#39;
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    expose:
      - &quot;2181&quot;
      - &quot;2888&quot;
      - &quot;32181&quot;
      - &quot;3888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    expose:
      - &quot;9092&quot;
      - &quot;29092&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  cloudera:
    image: midsw205/cdh-minimal:latest
    expose:
      - &quot;8020&quot; # nn
      - &quot;50070&quot; # nn http
      - &quot;8888&quot; # hue
    #ports:
    #- &quot;8888:8888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  spark:
    image: midsw205/spark-python:0.0.5
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;8888&quot;
    ports:
      - &quot;8888:8888&quot;
    depends_on:
      - cloudera
    environment:
      HADOOP_NAMENODE: cloudera
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;
    command: bash

  mids:
    image: midsw205/base:0.1.9
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;5000&quot;
    ports:
      - &quot;5000:5000&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;</code></pre>
<p>and with no need for a datafile on this one.</p>
<aside class="notes">

</aside>
</section>
<section id="spin-up-the-cluster" class="level2">
<h2>Spin up the cluster</h2>
<pre><code>docker-compose up -d</code></pre>
<aside class="notes">
<p>Now spin up the cluster</p>
<pre><code>docker-compose up -d</code></pre>
</aside>
</section>
<section id="create-a-topic-events" class="level2">
<h2>Create a topic <code>events</code></h2>
<pre><code>docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181</code></pre>
<aside class="notes">
<p>First, create a topic <code>events</code></p>
<pre><code>docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181</code></pre>
<p>which should show</p>
<pre><code>Created topic &quot;events&quot;.</code></pre>
</aside>
</section>
</section>
<section id="section-5" class="slide level1">
<h1></h1>
<section id="web-app" class="level2">
<h2>Web-app</h2>
<ul>
<li>Take our instrumented web-app from before <code>~/w205/full-stack/game_api.py</code></li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="im">from</span> kafka <span class="im">import</span> KafkaProducer</a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="im">from</span> flask <span class="im">import</span> Flask, request</a>
<a class="sourceLine" id="cb8-5" data-line-number="5"></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">app <span class="op">=</span> Flask(<span class="va">__name__</span>)</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">producer <span class="op">=</span> KafkaProducer(bootstrap_servers<span class="op">=</span><span class="st">&#39;kafka:29092&#39;</span>)</a>
<a class="sourceLine" id="cb8-8" data-line-number="8"></a>
<a class="sourceLine" id="cb8-9" data-line-number="9"></a>
<a class="sourceLine" id="cb8-10" data-line-number="10"><span class="kw">def</span> log_to_kafka(topic, event):</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">    event.update(request.headers)</a>
<a class="sourceLine" id="cb8-12" data-line-number="12">    producer.send(topic, json.dumps(event).encode())</a>
<a class="sourceLine" id="cb8-13" data-line-number="13"></a>
<a class="sourceLine" id="cb8-14" data-line-number="14"></a>
<a class="sourceLine" id="cb8-15" data-line-number="15"><span class="at">@app.route</span>(<span class="st">&quot;/&quot;</span>)</a>
<a class="sourceLine" id="cb8-16" data-line-number="16"><span class="kw">def</span> default_response():</a>
<a class="sourceLine" id="cb8-17" data-line-number="17">    default_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;default&#39;</span>}</a>
<a class="sourceLine" id="cb8-18" data-line-number="18">    log_to_kafka(<span class="st">&#39;events&#39;</span>, default_event)</a>
<a class="sourceLine" id="cb8-19" data-line-number="19">    <span class="cf">return</span> <span class="st">&quot;This is the default response!</span><span class="ch">\n</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb8-20" data-line-number="20"></a>
<a class="sourceLine" id="cb8-21" data-line-number="21"></a>
<a class="sourceLine" id="cb8-22" data-line-number="22"><span class="at">@app.route</span>(<span class="st">&quot;/purchase_a_sword&quot;</span>)</a>
<a class="sourceLine" id="cb8-23" data-line-number="23"><span class="kw">def</span> purchase_a_sword():</a>
<a class="sourceLine" id="cb8-24" data-line-number="24">    purchase_sword_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;purchase_sword&#39;</span>}</a>
<a class="sourceLine" id="cb8-25" data-line-number="25">    log_to_kafka(<span class="st">&#39;events&#39;</span>, purchase_sword_event)</a>
<a class="sourceLine" id="cb8-26" data-line-number="26">    <span class="cf">return</span> <span class="st">&quot;Sword Purchased!</span><span class="ch">\n</span><span class="st">&quot;</span></a></code></pre></div>
<aside class="notes">
<p>full blown one that adds in request headers</p>
</aside>
</section>
<section id="run-flask" class="level2">
<h2>run flask</h2>
<pre><code>docker-compose exec mids \
  env FLASK_APP=/w205/full-stack/game_api.py \
  flask run --host 0.0.0.0</code></pre>
<aside class="notes">
<pre><code>docker-compose exec mids env FLASK_APP=/w205/full-stack/game_api.py flask run --host 0.0.0.0</code></pre>
</aside>
</section>
<section id="set-up-to-watch-kafka" class="level2">
<h2>Set up to watch kafka</h2>
<pre><code>docker-compose exec mids \
  kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
<aside class="notes">
<ul>
<li>new terminal window, leave up</li>
<li>running kafkacat without -e so it will run continuously</li>
</ul>
<pre><code>docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
</aside>
</section>
<section id="apache-bench-to-generate-data" class="level2">
<h2>Apache Bench to generate data</h2>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<aside class="notes">
<ul>
<li>Choose to generate events with apache bench, curl from browser, but not mixing for now.</li>
<li>generating 10 events for now, can up that as much as needed, e.g., 100K</li>
</ul>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
</aside>
</section>
</section>
<section id="section-6" class="slide level1">
<h1></h1>
<section id="more-spark" class="level2">
<h2>More Spark</h2>
</section>
<section id="last-time" class="level2">
<h2>last time</h2>
<p><code>~/w205/spark-from-files/separate_events.py</code></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb21-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb21-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb21-7" data-line-number="7"></a>
<a class="sourceLine" id="cb21-8" data-line-number="8"></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;string&#39;</span>)</a>
<a class="sourceLine" id="cb21-10" data-line-number="10"><span class="kw">def</span> munge_event(event_as_json):</a>
<a class="sourceLine" id="cb21-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb21-12" data-line-number="12">    event[<span class="st">&#39;Host&#39;</span>] <span class="op">=</span> <span class="st">&quot;moe&quot;</span></a>
<a class="sourceLine" id="cb21-13" data-line-number="13">    event[<span class="st">&#39;Cache-Control&#39;</span>] <span class="op">=</span> <span class="st">&quot;no-cache&quot;</span></a>
<a class="sourceLine" id="cb21-14" data-line-number="14">    <span class="cf">return</span> json.dumps(event)</a>
<a class="sourceLine" id="cb21-15" data-line-number="15"></a>
<a class="sourceLine" id="cb21-16" data-line-number="16"></a>
<a class="sourceLine" id="cb21-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb21-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb21-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb21-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb21-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb21-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-23" data-line-number="23">        .getOrCreate()</a>
<a class="sourceLine" id="cb21-24" data-line-number="24"></a>
<a class="sourceLine" id="cb21-25" data-line-number="25">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb21-26" data-line-number="26">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb21-27" data-line-number="27">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-28" data-line-number="28">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-29" data-line-number="29">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-30" data-line-number="30">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-31" data-line-number="31">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-32" data-line-number="32">        .load()</a>
<a class="sourceLine" id="cb21-33" data-line-number="33"></a>
<a class="sourceLine" id="cb21-34" data-line-number="34">    munged_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb21-35" data-line-number="35">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb21-36" data-line-number="36">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-37" data-line-number="37">        .withColumn(<span class="st">&#39;munged&#39;</span>, munge_event(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb21-38" data-line-number="38"></a>
<a class="sourceLine" id="cb21-39" data-line-number="39">    extracted_events <span class="op">=</span> munged_events <span class="op">\</span></a>
<a class="sourceLine" id="cb21-40" data-line-number="40">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb21-41" data-line-number="41">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.munged))) <span class="op">\</span></a>
<a class="sourceLine" id="cb21-42" data-line-number="42">        .toDF()</a>
<a class="sourceLine" id="cb21-43" data-line-number="43"></a>
<a class="sourceLine" id="cb21-44" data-line-number="44">    sword_purchases <span class="op">=</span> extracted_events <span class="op">\</span></a>
<a class="sourceLine" id="cb21-45" data-line-number="45">        .<span class="bu">filter</span>(extracted_events.event_type <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>)</a>
<a class="sourceLine" id="cb21-46" data-line-number="46">    sword_purchases.show()</a>
<a class="sourceLine" id="cb21-47" data-line-number="47">    <span class="co"># sword_purchases \</span></a>
<a class="sourceLine" id="cb21-48" data-line-number="48">        <span class="co"># .write \</span></a>
<a class="sourceLine" id="cb21-49" data-line-number="49">        <span class="co"># .mode(&quot;overwrite&quot;) \</span></a>
<a class="sourceLine" id="cb21-50" data-line-number="50">        <span class="co"># .parquet(&quot;/tmp/sword_purchases&quot;)</span></a>
<a class="sourceLine" id="cb21-51" data-line-number="51"></a>
<a class="sourceLine" id="cb21-52" data-line-number="52">    default_hits <span class="op">=</span> extracted_events <span class="op">\</span></a>
<a class="sourceLine" id="cb21-53" data-line-number="53">        .<span class="bu">filter</span>(extracted_events.event_type <span class="op">==</span> <span class="st">&#39;default&#39;</span>)</a>
<a class="sourceLine" id="cb21-54" data-line-number="54">    default_hits.show()</a>
<a class="sourceLine" id="cb21-55" data-line-number="55">    <span class="co"># default_hits \</span></a>
<a class="sourceLine" id="cb21-56" data-line-number="56">        <span class="co"># .write \</span></a>
<a class="sourceLine" id="cb21-57" data-line-number="57">        <span class="co"># .mode(&quot;overwrite&quot;) \</span></a>
<a class="sourceLine" id="cb21-58" data-line-number="58">        <span class="co"># .parquet(&quot;/tmp/default_hits&quot;)</span></a>
<a class="sourceLine" id="cb21-59" data-line-number="59"></a>
<a class="sourceLine" id="cb21-60" data-line-number="60"></a>
<a class="sourceLine" id="cb21-61" data-line-number="61"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb21-62" data-line-number="62">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>single data frame created</li>
<li>filter on event type</li>
</ul>
</aside>
</section>
<section id="which-we-ran" class="level2">
<h2>which we ran</h2>
<pre><code>docker-compose exec spark \
  spark-submit /w205/spark-from-files/separate_events.py</code></pre>
<aside class="notes">
<pre><code>docker-compose exec spark spark-submit /w205/spark-from-files/separate_events.py</code></pre>
</aside>
</section>
<section id="what-if-different-event-types-have-different-schema" class="level2">
<h2>what if different event types have different schema?</h2>
</section>
<section id="section-7" class="level2">
<h2></h2>
<p><code>~/w205/full-stack/just_filtering.py</code></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb24-7" data-line-number="7"></a>
<a class="sourceLine" id="cb24-8" data-line-number="8"></a>
<a class="sourceLine" id="cb24-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb24-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb24-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb24-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb24-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb24-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb24-15" data-line-number="15"></a>
<a class="sourceLine" id="cb24-16" data-line-number="16"></a>
<a class="sourceLine" id="cb24-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb24-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb24-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb24-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb24-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb24-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-23" data-line-number="23">        .getOrCreate()</a>
<a class="sourceLine" id="cb24-24" data-line-number="24"></a>
<a class="sourceLine" id="cb24-25" data-line-number="25">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb24-26" data-line-number="26">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb24-27" data-line-number="27">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-28" data-line-number="28">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-29" data-line-number="29">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-30" data-line-number="30">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-31" data-line-number="31">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-32" data-line-number="32">        .load()</a>
<a class="sourceLine" id="cb24-33" data-line-number="33"></a>
<a class="sourceLine" id="cb24-34" data-line-number="34">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb24-35" data-line-number="35">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb24-36" data-line-number="36">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-37" data-line-number="37">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb24-38" data-line-number="38"></a>
<a class="sourceLine" id="cb24-39" data-line-number="39">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb24-40" data-line-number="40">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb24-41" data-line-number="41">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb24-42" data-line-number="42">        .toDF()</a>
<a class="sourceLine" id="cb24-43" data-line-number="43">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb24-44" data-line-number="44">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb24-45" data-line-number="45"></a>
<a class="sourceLine" id="cb24-46" data-line-number="46"></a>
<a class="sourceLine" id="cb24-47" data-line-number="47"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb24-48" data-line-number="48">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>usually going to have default responses with our events</li>
<li>so will have different schemas,</li>
<li>going to start doing filtering on the raw json before we explode it up into schema aware df</li>
<li>send it through boolean udf here to filter on event type</li>
<li>also write to hdfs as before</li>
<li>this is just one approach, whatâ€™s another?</li>
</ul>
</aside>
</section>
<section id="run-this" class="level2">
<h2>run this</h2>
<pre><code>docker-compose exec spark \
  spark-submit /w205/full-stack/just_filtering.py</code></pre>
<aside class="notes">
<pre><code>docker-compose exec spark spark-submit /w205/full-stack/just_filtering.py</code></pre>
</aside>
</section>
<section id="we-can-play-with-this" class="level2">
<h2>we can play with this</h2>
<p>add a new event type to the flask appâ€¦</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="at">@app.route</span>(<span class="st">&quot;/purchase_a_knife&quot;</span>)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw">def</span> purchase_a_knife():</a>
<a class="sourceLine" id="cb27-3" data-line-number="3">    purchase_knife_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;purchase_knife&#39;</span>,</a>
<a class="sourceLine" id="cb27-4" data-line-number="4">                            <span class="st">&#39;description&#39;</span>: <span class="st">&#39;very sharp knife&#39;</span>}</a>
<a class="sourceLine" id="cb27-5" data-line-number="5">    log_to_kafka(<span class="st">&#39;events&#39;</span>, purchase_knife_event)</a>
<a class="sourceLine" id="cb27-6" data-line-number="6">    <span class="cf">return</span> <span class="st">&quot;Knife Purchased!</span><span class="ch">\n</span><span class="st">&quot;</span></a></code></pre></div>
<aside class="notes">
<ul>
<li>optional</li>
<li>can experiment with different event types</li>
<li>ok with data already in kafka</li>
<li>now trick is how do we get that all the way through spark</li>
</ul>
</aside>
</section>
</section>
<section id="section-8" class="slide level1">
<h1></h1>
<section id="write-events" class="level2">
<h2>Write Events</h2>
<aside class="notes">

</aside>
</section>
<section id="section-9" class="level2">
<h2></h2>
<p><code>full-stack/filtered_writes.py</code></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb28-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb28-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb28-7" data-line-number="7"></a>
<a class="sourceLine" id="cb28-8" data-line-number="8"></a>
<a class="sourceLine" id="cb28-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb28-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb28-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb28-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb28-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb28-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb28-15" data-line-number="15"></a>
<a class="sourceLine" id="cb28-16" data-line-number="16"></a>
<a class="sourceLine" id="cb28-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb28-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb28-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb28-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb28-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb28-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-23" data-line-number="23">        .getOrCreate()</a>
<a class="sourceLine" id="cb28-24" data-line-number="24"></a>
<a class="sourceLine" id="cb28-25" data-line-number="25">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb28-26" data-line-number="26">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb28-27" data-line-number="27">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-28" data-line-number="28">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-29" data-line-number="29">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-30" data-line-number="30">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-31" data-line-number="31">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-32" data-line-number="32">        .load()</a>
<a class="sourceLine" id="cb28-33" data-line-number="33"></a>
<a class="sourceLine" id="cb28-34" data-line-number="34">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb28-35" data-line-number="35">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb28-36" data-line-number="36">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-37" data-line-number="37">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb28-38" data-line-number="38"></a>
<a class="sourceLine" id="cb28-39" data-line-number="39">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb28-40" data-line-number="40">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb28-41" data-line-number="41">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-42" data-line-number="42">        .toDF()</a>
<a class="sourceLine" id="cb28-43" data-line-number="43">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb28-44" data-line-number="44">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb28-45" data-line-number="45"></a>
<a class="sourceLine" id="cb28-46" data-line-number="46">    extracted_purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb28-47" data-line-number="47">        .write <span class="op">\</span></a>
<a class="sourceLine" id="cb28-48" data-line-number="48">        .mode(<span class="st">&#39;overwrite&#39;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb28-49" data-line-number="49">        .parquet(<span class="st">&#39;/tmp/purchases&#39;</span>)</a>
<a class="sourceLine" id="cb28-50" data-line-number="50"></a>
<a class="sourceLine" id="cb28-51" data-line-number="51"></a>
<a class="sourceLine" id="cb28-52" data-line-number="52"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb28-53" data-line-number="53">    main()</a></code></pre></div>
<aside class="notes">

</aside>
</section>
<section id="run-this-1" class="level2">
<h2>run this</h2>
<pre><code>docker-compose exec spark \
  spark-submit /w205/full-stack/filtered_writes.py</code></pre>
<aside class="notes">
<pre><code>docker-compose exec spark spark-submit /w205/full-stack/filtered_writes.py</code></pre>
</aside>
</section>
<section id="should-see-purchases-in-hdfs" class="level2">
<h2>should see purchases in hdfs</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/purchases/</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-10" class="slide level1">
<h1></h1>
<section id="queries-from-spark" class="level2">
<h2>Queries From Spark</h2>
<aside class="notes">

</aside>
</section>
<section id="spin-up-a-notebook" class="level2">
<h2>spin up a notebook</h2>
<pre><code>docker-compose exec spark \
  env \
    PYSPARK_DRIVER_PYTHON=jupyter \
    PYSPARK_DRIVER_PYTHON_OPTS=&#39;notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root&#39; \
  pyspark</code></pre>
<aside class="notes">
<pre><code>docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS=&#39;notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root&#39; pyspark</code></pre>
<ul>
<li>use a notebook as our pyspark driver</li>
</ul>
</aside>
</section>
<section id="new-python3-notebook-and-play" class="level2">
<h2>New python3 notebook and play</h2>
<pre><code>purchases = spark.read.parquet(&#39;/tmp/purchases&#39;)
purchases.show()
purchases.registerTempTable(&#39;purchases&#39;)
purchases_by_example2 = spark.sql(&quot;select * from purchases where Host = &#39;user2.att.com&#39;&quot;)
purchases_by_example2.show()
newdf = purchases_by_example2.toPandas()
newdf.describe()</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-11" class="slide level1">
<h1></h1>
<section id="down" class="level2">
<h2>down</h2>
<pre><code>docker-compose down</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-12" class="slide level1">
<h1></h1>
<section id="secureshell-ssh" class="level2">
<h2>SecureShell (SSH)</h2>
</section>
</section>
<section id="section-13" class="slide level1">
<h1></h1>
<section id="remote-terminal-connections" class="level2">
<h2>remote terminal connections</h2>
</section>
<section id="section-14" class="level2">
<h2></h2>
<pre><code>ssh science@xxx.xxx.xxx.xxx</code></pre>
<aside class="notes">
<p>for your cloud instance, look up: - the ip address - password for the <code>science</code> user</p>
</aside>
</section>
</section>
<section id="section-15" class="slide level1">
<h1></h1>
<section id="copying-files" class="level2">
<h2>copying files</h2>
</section>
<section id="section-16" class="level2">
<h2></h2>
<p>On your laptop, run</p>
<pre><code>scp some_file science@xxx.xxx.xxx.xxx:</code></pre>
<p>or</p>
<pre><code>scp some_file science@xxx.xxx.xxx.xxx:/tmp/</code></pre>
<aside class="notes">
<p>copying files from your laptop to the instance</p>
<p>note the colon!</p>
</aside>
</section>
<section id="section-17" class="level2">
<h2></h2>
<p>On your laptop, run</p>
<pre><code>scp science@xxx.xxx.xxx.xxx:~/w205/a_file.py .</code></pre>
<aside class="notes">
<p>copying files from the instance to your laptop</p>
<p>note the period!</p>
</aside>
</section>
</section>
<section id="section-18" class="slide level1">
<h1></h1>
<section id="keys" class="level2">
<h2>keys</h2>
<aside class="notes">
<p>passwords suckâ€¦ use keys</p>
</aside>
</section>
<section id="generate-a-keypair" class="level2">
<h2>generate a keypair</h2>
<pre><code>ssh-keygen -t rsa -b 2048</code></pre>
<aside class="notes">
<p>hit return at all the prompts</p>
<p>windows usersâ€¦ use a bash shell please</p>
</aside>
</section>
<section id="this-creates" class="level2">
<h2>this creates</h2>
<p>a public key</p>
<pre><code>~/.ssh/id_rsa.pub</code></pre>
<p>and a secret key</p>
<pre><code>~/.ssh/id_rsa</code></pre>
<aside class="notes">
<p>public key safe to share/post</p>
</aside>
</section>
<section id="add-your-pubkey-to-github" class="level2">
<h2>add your pubkey to github</h2>
</section>
<section id="verify-your-pubkey-is-on-github" class="level2">
<h2>verify your pubkey is on github</h2>
<pre><code>curl https://github.com/&lt;your-gh-id&gt;.keys</code></pre>
<p>(note the <code>https</code>!)</p>
<aside class="notes">
<p>now no more passwords for git commands</p>
</aside>
</section>
<section id="add-pubkey-to-instance" class="level2">
<h2>add pubkey to instance</h2>
<p>On your cloud instance, run</p>
<pre><code>ssh-import-id-gh &lt;your-gh-id&gt;</code></pre>
<aside class="notes">

</aside>
</section>
<section id="you-should-see-something-like" class="level2">
<h2>you should see something like</h2>
<pre><code>science@smmm-mmm-1:~$ ssh-import-id-gh mmm
2018-04-02 18:09:29,091 INFO Starting new HTTPS connection (1): api.github.com
2018-04-02 18:09:29,285 INFO Authorized key [&#39;4096&#39;, &#39;SHA256:51JGHgluZZRHkyxT9rA5FGi0fIX2/Nm4wCaeu7GsiN0&#39;, &#39;mmm@github/26661056&#39;, &#39;(RSA)&#39;]
2018-04-02 18:09:29,287 INFO [1] SSH keys [Authorized]  </code></pre>
</section>
<section id="now-no-more-passwords" class="level2">
<h2>now no more passwords</h2>
<pre><code>ssh science@xxx.xxx.xxx.xxx</code></pre>
<aside class="notes">
<p>from your laptop</p>
</aside>
</section>
</section>
<section id="section-19" class="slide level1">
<h1></h1>
<section id="summary" class="level2">
<h2>Summary</h2>
</section>
</section>
<section id="section-20" class="slide level1">
<h1></h1>
<p><img class="logo" src="images/berkeley-school-of-information-logo.png"/></p>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Transition style
        transition: 'linear', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
