# MIDS w205 - Fundamentals of Data Engineering 
### Spring 2018

## Course Description

Storing, managing, and processing datasets are foundational processes in data
science. This course introduces the fundamental knowledge and skills of data
engineering that are required to be effective as a data scientist. This course
focuses on the basics of data pipelines, data pipeline flows and associated
business use cases, and how organizations derive value from data and data
engineering.  As these fundamentals of data engineering are introduced,
learners will interact with data and data processes at various stages in the
pipeline, understand key data engineering tools and platforms, and use and
connect critical technologies through which one can construct storage and
processing architectures that underpin data science applications.

##Course Format

The course is organized as an online inverted classroom. During each week, students first
work through a set of asynchronous materials, including video lectures, readings, and other
activities. Once a week, students meet for a 90-minute live session, in which they connect with
an instructor and other students in an online classroom. A functioning webcam and an audio
headset are required to participate in the live sessions. Students must complete all assigned
asynchronous material before the scheduled live session begins.

## Course Objectives

###Tools and Technologies

Students will:

- Build practical experience building data pipelines.
- Build practical experience cleaning, anonymizing, and plumbing data.
- Learn tooling for queries and query management (e.g., BigQuery, SQL).
- Learn tooling for analytics (jupyter, python, py-based-libs).
- Get exposure to advanced tooling for analytics (spark, kafka, etc).
- Learn how to leverage revision control.
- Learn how to use docker to assemble common tools for analysis.
- Build practical experience leveraging cloud-based resources for data analytics.
- Build practical experience consuming data and services from APIs.
- Get exposure to events and event-log based analytics.

###Concepts

Students will:

- Learn to keep their analysis grounded in busines relevence.
- Get exposure to some basic distributed storage and compute concepts.
- Get exposure to some basic RDBMS concepts.
- Get exposre to RDB -vs- NoSQL tooling and approaches.
- Get exposure to some basic data warehousing concepts.
- Learn the basics of virtualization and containerization.
- Understand how analysis changes wrt scale / complexity of data.
- Learn about data partitioning.
- Learn about latency in data analysis.
- Get exposure to ETL -vs- NoETL.
- Learn the basic concepts of web-based applications.
- Understand how basic data privacy, security, and chain-of-custody works.


## Assignments

The assignments will cumulatively build into 3 projects: the Query Project, the Tracking User Activity Project and the Understanding User Behavior Project. Each assignment will be a part of one of these projects. Each assignment will be a hands-on lab that is completed both individually and revisited during the synchronous weekly group sessions. The details of the assignments and readings are available for each course section on the course wall.

## Prerequisites:

- Previous experience with Python.
- Basic knowledge of Unix/Linux commands and tools as well as concepts such as processes, file systems.

## Course Outline
The course consists of 4 sections: A 3-week Introduction that covers the basics
of storage and retrieval concepts and tools; a 5-week Basics section that
provides a deeper exploration of working with data and data pipelines; a 4-week
section that focuses on Streaming Data; and a concluding section, Putting it
All Together, that integrates concepts and skills from the entire course into a
cohesive model of the data pipeline.

In addition to the sequenced material covered, the course also includes
Tutorial materials that focus on technical skills associated with data
engineering technologies, tools, and platforms. These tutorials also provide a
practical foundation for the discussions and activities that will take place in
the live classroom for specific weeks in the term.

# Introduction

## Week 01 - Introduction

#### Themes: What is Data Engineering? Gathering event data. Get started with queries.



## Week 02 - Working with Data

#### Themes: Intro to data, metadata, and some basic tools for working with data.



## Week 03 - Welcome to the Queryside

#### Themes: SQL, query tools



# The Basics

## Week 04 - Storing Data

#### Themes: Relational and NoSQL datastores


## Week 05 - Storing Data II

#### Themes: Introduction to cloud concepts and Hadoop


## Week 06 - Transforming Data

#### Themes: ETL and its discontents, more Hadoop, and container management


## Week 07 - Sourcing Data

#### Themes: Data and its provenance, security and privacy


## Week 08 - Querying Data

#### Themes: Querying with partition keys and query planning


# Streaming

## Week 09 - Ingesting Data

#### Themes: Ingesting streaming data, using Kafka, considerations of latency


## Week 10 - Transforming Streaming Data

#### Themes: NoETL, batch vs streaming, in-memory computing


## Week 11 - Faster Data Stores

#### Themes: Distributed in-memory storage and Spark


## Week 12 - Faster Queries

#### Themes: Structured streaming, streaming queries, caching vs. stream queries


# Putting it All Together

## Week 13 - Understanding Data

#### Themes: Sessionization and state and model validation and management


## Week 14 - Patterns for Data Pipelines

#### Themes: Conceptual DevOps and serverless architectures


## Academic Integrity
Please read UC Berkeleyâ€™s policies around academic integrity:
http://sa.berkeley.edu/conduct/integrity

## Avoiding Plagiarism
Plagiarism is a serious academic offense, and students must take care not to copy code written by others. Beginning students sometimes have trouble identifying exactly when plagiarism takes place. Remember that it is generally fine to search for examples of code (for example, on forums like stackoverflow). This is a normal part of programming and can help you learn. However, it is important that you understand the code you find and use what you learn to write your own statements. If in doubt, simply document the place you found your example code and ask your instructors for further guidance.

---
